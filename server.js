/**
 * server.js
 * Real Estate Voice Agent - FINAL OPTIMIZED
 * 
 * FIXES:
 * - English greeting from the start
 * - Better Deepgram detection (nova-2 â†’ nova-3)
 * - Improved speech recognition
 * - Fast and responsive
 */

require("dotenv").config();

const express = require("express");
const http = require("http");
const WebSocket = require("ws");
const twilio = require("twilio");
const { createClient, LiveTranscriptionEvents } = require("@deepgram/sdk");
const OpenAI = require("openai");

/* =========================
   ENV VALIDATION
========================= */
const {
  TWILIO_ACCOUNT_SID,
  TWILIO_AUTH_TOKEN,
  DEEPGRAM_API_KEY,
  OPENAI_API_KEY,
  RENDER_EXTERNAL_URL,
  LOCAL_TEST,
} = process.env;

if (!TWILIO_ACCOUNT_SID) throw new Error("âŒ Missing TWILIO_ACCOUNT_SID");
if (!TWILIO_AUTH_TOKEN) throw new Error("âŒ Missing TWILIO_AUTH_TOKEN");
if (!DEEPGRAM_API_KEY) throw new Error("âŒ Missing DEEPGRAM_API_KEY");
if (!OPENAI_API_KEY) throw new Error("âŒ Missing OPENAI_API_KEY");
if (!RENDER_EXTERNAL_URL) throw new Error("âŒ Missing RENDER_EXTERNAL_URL");

console.log("âœ… All environment variables present");

/* =========================
   CLIENTS
========================= */
const deepgram = createClient(DEEPGRAM_API_KEY);
const openai = new OpenAI({ apiKey: OPENAI_API_KEY });

/* =========================
   SERVER
========================= */
const app = express();
const server = http.createServer(app);
const wss = new WebSocket.Server({ server, path: "/ws" });
const { VoiceResponse } = twilio.twiml;

app.use(express.urlencoded({ extended: false }));
app.use(express.json());

/* =========================
   OPTIMIZED TIMING
========================= */
const MIN_CHARS = 3;
const MAX_HISTORY = 10;
const UTTERANCE_END_MS = 700;       // Balanced (not too fast, not too slow)
const ENDPOINTING_MS = 250;         // Good detection
const SAFETY_TIMEOUT = 1500;        // 1.5s backup

/* =========================
   HELPERS
========================= */
function baseUrl() {
  return RENDER_EXTERNAL_URL.startsWith("http")
    ? RENDER_EXTERNAL_URL
    : `https://${RENDER_EXTERNAL_URL}`;
}

function wsUrl() {
  if (LOCAL_TEST === "true") {
    return "ws://localhost:10000/ws";
  }
  const url = new URL(baseUrl());
  return `wss://${url.host}/ws`;
}

/* =========================
   ROUTES
========================= */
app.get("/", (req, res) => {
  res.send("âœ… Real Estate Voice Agent Active");
});

app.get("/health", (req, res) => {
  res.json({
    status: "ok",
    timestamp: new Date().toISOString(),
    service: "voice-agent"
  });
});

/* =========================
   TWILIO WEBHOOK - ENGLISH GREETING
========================= */
app.post("/voice", (req, res) => {
  console.log("\nğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
  console.log("ğŸ“ NEW INCOMING CALL");
  console.log("ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
  console.log("ğŸ“± From:", req.body.From);
  console.log("ğŸ“± CallSid:", req.body.CallSid);
  console.log("ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

  const vr = new VoiceResponse();

  // âœ… ENGLISH GREETING FROM START
  vr.say(
    { voice: "Polly.Joanna", language: "en-US" },
    "Hello, this is Ava from Prestige Real Estate. How can I help you today?"
  );

  // Start WebSocket stream
  vr.start().stream({ url: wsUrl() });
  vr.pause({ length: 60 });

  res.type("text/xml").send(vr.toString());
});

/* =========================
   GPT - CONCISE & FAST
========================= */
async function askGPT({ conversationHistory, memory }) {
  try {
    const systemPrompt = {
      role: "system",
      content: `You are Ava, a real estate phone assistant at Prestige Real Estate.

Your role:
- Help people BUY or SELL houses
- You DO NOT handle rentals
- Be concise and guide the conversation

Memory:
- Name: ${memory.name || "unknown"}
- Intent: ${memory.intent || "unknown - ask if BUY or SELL"}
- Budget: ${memory.budget || "unknown"}
- Location: ${memory.location || "unknown"}

Rules:
- Speak in ENGLISH
- Keep responses SHORT (1-2 sentences)
- Ask ONE question at a time
- Be proactive and friendly
- If asked about rentals â†’ redirect to buying/selling
- If caller repeats â†’ acknowledge and move forward
- Never mention being AI

Memory format:
Start with: [MEM: name=John, intent=BUY, budget=500000]
Then your response.

Examples:
User: "Do you have houses to rent?"
You: "I specialize in buying and selling. Are you looking to buy or sell a property?"

User: "I want to buy"
You: [MEM: intent=BUY] "Great! What area are you interested in?"

User: "Around $400k in Miami"
You: [MEM: budget=400000, location=Miami] "Perfect! When are you looking to buy?"

Be natural, brief, and action-oriented.`
    };

    const messages = [systemPrompt, ...conversationHistory];

    const stream = await openai.chat.completions.create({
      model: "gpt-4o",
      temperature: 0.6,
      max_tokens: 100,
      stream: true,
      messages: messages,
    });

    let fullResponse = "";
    for await (const chunk of stream) {
      const content = chunk.choices[0]?.delta?.content || "";
      fullResponse += content;
    }

    return fullResponse.trim();

  } catch (e) {
    console.error("âŒ GPT error:", e.message);
    return "Sorry, could you repeat that please?";
  }
}

/* =========================
   PARSE MEMORY
========================= */
function parseMemoryUpdate(response, memory) {
  const memMatch = response.match(/\[MEM:\s*([^\]]+)\]/);
  
  if (memMatch) {
    const updates = memMatch[1];
    const cleanResponse = response.replace(/\[MEM:[^\]]+\]\s*/, "").trim();
    
    updates.split(",").forEach(pair => {
      const [key, ...valueParts] = pair.split("=");
      const value = valueParts.join("=").trim();
      const cleanKey = key.trim();
      
      if (memory.hasOwnProperty(cleanKey) && value && value !== "null") {
        memory[cleanKey] = value;
        console.log(`   ğŸ“ Memory: ${cleanKey} = ${value}`);
      }
    });
    
    return cleanResponse;
  }
  
  return response;
}

/* =========================
   WEBSOCKET
========================= */
wss.on("connection", (ws) => {
  console.log("\nğŸ”Œ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
  console.log("ğŸ”Œ NEW MEDIA CONNECTION");
  console.log("ğŸ”Œ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");

  let utteranceBuffer = "";
  let isProcessing = false;
  let isSpeaking = false;
  let safetyTimer = null;
  let callSid = null;
  let lastUserText = "";

  const memory = {
    name: null,
    intent: null,
    budget: null,
    location: null,
  };

  const conversationHistory = [];

  /* =========
     HANDLE USER SPEECH
  ========= */
  async function handleUserUtterance(text) {
    if (text.length < MIN_CHARS) {
      console.log(`   âš ï¸ Too short: ${text.length} chars`);
      return;
    }
    
    if (isProcessing) {
      console.log("   â³ Already processing");
      return;
    }

    // Anti-repetition
    if (text === lastUserText) {
      console.log("   ğŸ” Repeated - moving forward");
    }
    lastUserText = text;

    isProcessing = true;
    console.log(`\nğŸ‘¤ USER: "${text}"`);

    try {
      conversationHistory.push({
        role: "user",
        content: text
      });

      const rawResponse = await askGPT({
        conversationHistory,
        memory
      });

      const cleanResponse = parseMemoryUpdate(rawResponse, memory);

      conversationHistory.push({
        role: "assistant",
        content: cleanResponse
      });

      if (conversationHistory.length > MAX_HISTORY) {
        conversationHistory.splice(0, 2);
      }

      console.log(`ğŸ¤– AVA: "${cleanResponse}"`);
      console.log(`ğŸ§  Memory:`, JSON.stringify(memory, null, 2));

      // TODO: Send to TTS
      // await sendToTTS(cleanResponse, ws);

    } catch (error) {
      console.error("âŒ Error:", error.message);
    } finally {
      isProcessing = false;
    }
  }

  /* =========
     DEEPGRAM - IMPROVED DETECTION
  ========= */
  const dg = deepgram.listen.live({
    model: "nova-3",  // âœ… Better model (was nova-2)
    language: "en-US",  // âœ… English primary (was "multi")
    encoding: "mulaw",
    sample_rate: 8000,
    smart_format: true,
    interim_results: true,
    utterance_end_ms: UTTERANCE_END_MS,
    vad_events: true,
    endpointing: ENDPOINTING_MS,
    punctuate: true,  // âœ… Better transcription
    diarize: false,
  });

  console.log("ğŸ¤ Deepgram connected (nova-3, en-US)");

  /* =========
     DEEPGRAM EVENTS
  ========= */

  dg.on(LiveTranscriptionEvents.Transcript, (data) => {
    const transcript = data.channel?.alternatives?.[0]?.transcript || "";
    if (!transcript) return;

    // Show interim
    if (!data.is_final && transcript.length > 0) {
      process.stdout.write(`\r   ğŸ¤ [interim] ${transcript}                    `);
    }

    // Accumulate final
    if (data.is_final) {
      utteranceBuffer += " " + transcript;
      console.log(`\r   âœ… [final] ${transcript}`);
      
      clearTimeout(safetyTimer);
      safetyTimer = setTimeout(() => {
        const trimmed = utteranceBuffer.trim();
        if (trimmed) {
          console.log("   â° Safety timeout");
          handleUserUtterance(trimmed);
          utteranceBuffer = "";
        }
      }, SAFETY_TIMEOUT);
    }
  });

  dg.on(LiveTranscriptionEvents.UtteranceEnd, (data) => {
    clearTimeout(safetyTimer);
    
    const finalText = utteranceBuffer.trim();
    utteranceBuffer = "";

    if (finalText) {
      console.log("   âœ… UtteranceEnd detected");
      handleUserUtterance(finalText);
    }
  });

  dg.on(LiveTranscriptionEvents.SpeechStarted, () => {
    console.log("   ğŸ¤ Speech started");
    
    if (isSpeaking) {
      console.log("   âš ï¸ Interrupted");
      isSpeaking = false;
      // TODO: Stop TTS
    }
  });

  dg.on(LiveTranscriptionEvents.Error, (error) => {
    console.error("âŒ Deepgram error:", error);
  });

  dg.on(LiveTranscriptionEvents.Close, () => {
    console.log("ğŸ”’ Deepgram closed");
  });

  /* =========
     TWILIO WEBSOCKET
  ========= */
  ws.on("message", (msg) => {
    try {
      const data = JSON.parse(msg);

      if (data.event === "media") {
        dg.send(Buffer.from(data.media.payload, "base64"));
      }

      if (data.event === "start") {
        callSid = data.start.callSid;
        console.log(`ğŸ“ Call started: ${callSid}`);
      }

      if (data.event === "stop") {
        console.log("\nğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
        console.log("ğŸ“ CALL ENDED");
        console.log(`ğŸ“¡ CallSid: ${callSid}`);
        console.log(`â±ï¸  Exchanges: ${conversationHistory.length / 2}`);
        console.log("ğŸ“Š SUMMARY:");
        console.log(JSON.stringify(memory, null, 2));
        console.log("ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
      }

    } catch (e) {
      console.error("âŒ WebSocket error:", e.message);
    }
  });

  ws.on("close", () => {
    clearTimeout(safetyTimer);
    dg.finish();
    console.log("ğŸ”’ WebSocket closed");
  });

  ws.on("error", (error) => {
    console.error("âŒ WebSocket error:", error.message);
  });
});

/* =========================
   ERROR HANDLING
========================= */
process.on("uncaughtException", (error) => {
  console.error("ğŸ’¥ Uncaught exception:", error);
});

process.on("unhandledRejection", (reason, promise) => {
  console.error("ğŸ’¥ Unhandled rejection:", reason);
});

/* =========================
   START
========================= */
const PORT = process.env.PORT || 10000;

server.listen(PORT, "0.0.0.0", () => {
  console.log("\nğŸš€ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
  console.log("ğŸš€ VOICE AGENT STARTED");
  console.log("ğŸš€ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
  console.log(`ğŸ“¡ Port: ${PORT}`);
  console.log(`ğŸŒ URL: ${baseUrl()}`);
  console.log(`ğŸ”Œ WebSocket: ${wsUrl()}`);
  console.log(`ğŸ“ Webhook: ${baseUrl()}/voice`);
  console.log("ğŸš€ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
  console.log("âœ… Ready for calls\n");
});